% bib file

% Start with your annual review article



@article{mitchellAlgorithmicFairnessChoices2021,
	title = {Algorithmic Fairness: Choices, Assumptions, and Definitions},
	volume = {8},
	issn = {2326-8298, 2326-831X},
	url = {https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-042720-125902},
	doi = {10.1146/annurev-statistics-042720-125902},
	shorttitle = {Algorithmic Fairness},
	abstract = {A recent wave of research has attempted to define fairness quantitatively. In particular, this work has explored what fairness might mean in the context of decisions based on the predictions of statistical and machine learning models. The rapid growth of this new field has led to wildly inconsistent motivations, terminology, and notation, presenting a serious challenge for cataloging and comparing definitions. This article attempts to bring much-needed order. First, we explicate the various choices and assumptions made—often implicitly—to justify the use of prediction-based decision-making. Next, we show how such choices and assumptions can raise fairness concerns and we present a notationally consistent catalog of fairness definitions from the literature. In doing so, we offer a concise reference for thinking through the choices, assumptions, and fairness considerations of prediction-based decision-making.},
	pages = {141--163},
	issue = {Volume 8, 2021},
	journaltitle = {Annual Review of Statistics and Its Application},
	publisher = {Annual Reviews},
	author = {Mitchell, Shira and Potash, Eric and Barocas, Solon and D'Amour, Alexander and Lum, Kristian},
	urldate = {2026-01-30},
	date = {2021-03-07},
	langid = {english},
	file = {Full Text:C\:\\Users\\gkcam\\Zotero\\storage\\IXN9WMYG\\Mitchell et al. - 2021 - Algorithmic Fairness Choices, Assumptions, and Definitions.pdf:application/pdf;Snapshot:C\:\\Users\\gkcam\\Zotero\\storage\\QIQZ3D8M\\annurev-statistics-042720-125902.html:text/html},
}


@article{caldersThreeNaiveBayes2010,
	title = {Three naive Bayes approaches for discrimination-free classification},
	volume = {21},
	issn = {1573-756X},
	url = {https://doi.org/10.1007/s10618-010-0190-x},
	doi = {10.1007/s10618-010-0190-x},
	abstract = {In this paper, we investigate how to modify the naive Bayes classifier in order to perform classification that is restricted to be independent with respect to a given sensitive attribute. Such independency restrictions occur naturally when the decision process leading to the labels in the data-set was biased; e.g., due to gender or racial discrimination. This setting is motivated by many cases in which there exist laws that disallow a decision that is partly based on discrimination. Naive application of machine learning techniques would result in huge fines for companies. We present three approaches for making the naive Bayes classifier discrimination-free: (i) modifying the probability of the decision being positive, (ii) training one model for every sensitive attribute value and balancing them, and (iii) adding a latent variable to the Bayesian model that represents the unbiased label and optimizing the model parameters for likelihood using expectation maximization. We present experiments for the three approaches on both artificial and real-life data.},
	pages = {277--292},
	number = {2},
	journaltitle = {Data Mining and Knowledge Discovery},
	shortjournal = {Data Min Knowl Disc},
	author = {Calders, Toon and Verwer, Sicco},
	urldate = {2026-01-30},
	date = {2010-09-01},
	langid = {english},
	keywords = {Discrimination-aware classification, Expectation maximization, Naive Bayes},
}

@article{courchaneLessonsLearnedStatistical2000,
	title = {Lessons Learned: Statistical Techniques and Fair Lending},
	volume = {11},
	issn = {1052-7001},
	url = {https://www.jstor.org/stable/24833783},
	shorttitle = {Lessons Learned},
	abstract = {There remains strong concern that, even after several years of intense scrutiny, lending discrimination persists. The concerns encompass issues of lending denial disparities, use of predatory lending tactics, and potential disparate impact arising from increased use of credit scoring. This article specifically addresses disparate treatment of loan applications by analyzing data collected in fair lending examinations conducted at national banks during the period 1994 through mid-1999. This information will be useful to banks interested in monitoring their performance, to consumers interested in determining factors that influence their ability to purchase homes, and to policy makers concerned with discrimination issues. We find that statistical analysis can be used successfully to identify patterns of discrimination and that custom modeling, used to reflect an individual bank's underwriting policies, is most effective for that purpose and we discuss variables found to be most predictive of the lending decision. We also suggest potential improvements in the examination of fair lending and identify areas that deserve additional research, given improved data availability.},
	pages = {277--295},
	number = {2},
	journaltitle = {Journal of Housing Research},
	publisher = {American Real Estate Society},
	author = {Courchane, Marsha and Nebhut, David and Nickerson, David},
	urldate = {2026-01-30},
	date = {2000},
}


% Below that, add bibtex for your sources
